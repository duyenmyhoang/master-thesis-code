{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_origin_dataset():\n",
    "    file_path = r\"C:\\Users\\Q672355\\OneDrive\\MA\\Daten\\2024-12-22_detailed_query_alternatives_segments.csv\"\n",
    "    df = pd.read_csv(file_path, sep=\",\", encoding=\"utf-8\")\n",
    "\n",
    "    # Remove corrupted trips\n",
    "    df = df[df[\"Vehicle ID\"].notnull()]\n",
    "    df.dropna(subset=[\"Vehicle ID\", \"Trip Segments Location Address\"], inplace=True)\n",
    "\n",
    "    # Transform data\n",
    "    trips_data = []\n",
    "\n",
    "    for _, trips in df.groupby(\"Trip ID\"):\n",
    "        t = trips.iloc[0]\n",
    "        if pd.isna(t[\"Trip Segments Timestamp\"]):\n",
    "            continue\n",
    "        # Extract the general information\n",
    "        date = t[\"Trip Segments Timestamp\"].split(\" \")[0]\n",
    "        data = {\n",
    "            \"vehicle_id\": int(t[\"Vehicle ID\"]),\n",
    "            \"efficient_mode\": float(t[\"Efficient Mode\"]),\n",
    "            \"vehicle_type\": t[\"Vehicle Type\"] if not pd.isna(t[\"Vehicle Type\"]) else \"BE\",\n",
    "            \"electric_consumption\": float(t[\"Electric Consumption\"]),\n",
    "            \"fuel_consumption\": float(t[\"Fuel Consumption\"]),\n",
    "            \"speed\": float(t[\"Speed Average\"]),\n",
    "            \"distance\": float(t[\"Distance\"]),\n",
    "            \"date\": date,\n",
    "            \"weekday\": pd.Timestamp(date).strftime(\"%A\"),\n",
    "            \"app_open_count\": (\n",
    "                0 if pd.isna(t[\"User App Open Count\"])\n",
    "                else int(t[\"User App Open Count\"])\n",
    "            ),\n",
    "        }\n",
    "\n",
    "        # Merge into a single trip\n",
    "        for trip_alternative_type, trip in trips.groupby(\"Trip Alternatives Type\"):\n",
    "            # Make sure that there are start and end in one trip\n",
    "            if len(trip) != 2:\n",
    "                continue\n",
    "\n",
    "            # Determine the start and end trips\n",
    "            start = trip[trip[\"Trip Segments Type\"] == \"start\"]\n",
    "            if len(start.index) != 1:\n",
    "                continue\n",
    "            else:\n",
    "                start = start.iloc[0]\n",
    "            end = trip[trip[\"Trip Segments Type\"] == \"end\"]\n",
    "            if len(end.index) != 1:\n",
    "                continue\n",
    "            else:\n",
    "                end = end.iloc[0]\n",
    "            \n",
    "            # Determine whether trip is in Netherland\n",
    "            start_location = start[\"Trip Segments Location Address\"]\n",
    "            end_location = end[\"Trip Segments Location Address\"]\n",
    "            if not start_location.endswith(\"Netherlands\") and not end_location.endswith(\"Netherlands\"):\n",
    "                continue\n",
    "\n",
    "            data[\"start_time\"] = start[\"Trip Segments Timestamp\"].split(\" \")[1][:5]\n",
    "            data[\"start_time\"] = date + \" \" + data[\"start_time\"]\n",
    "            data[\"end_time\"] = end[\"Trip Segments Timestamp\"].split(\" \")[1][:5]\n",
    "            data[\"end_time\"] = date + \" \" + data[\"end_time\"]\n",
    "            data[\"start_location\"] = start[\"Trip Segments Location Address\"]\n",
    "            data[\"end_location\"] = end[\"Trip Segments Location Address\"]\n",
    "            data[\"start_lng\"] = start[\"Trip Segments Location Lng\"]\n",
    "            data[\"start_lat\"] = start[\"Trip Segments Location Lat\"]\n",
    "            data[\"end_lng\"] = end[\"Trip Segments Location Lng\"]\n",
    "            data[\"end_lat\"] = end[\"Trip Segments Location Lat\"]\n",
    "            data[f\"distance_{trip_alternative_type}\"] = float(start[\"Trip Alternatives Distance\"])\n",
    "            data[f\"distance_diff_{trip_alternative_type}\"] = float(start[\"Trip Alternatives Distance Diff\"])\n",
    "            data[f\"time_diff_{trip_alternative_type}\"] = int(start[\"Trip Alternatives Time Diff\"])\n",
    "            data[f\"is_{trip_alternative_type}_good_alternative\"] = (\n",
    "                0 if pd.isna(start[\"Trip Alternatives Is Good\"])\n",
    "                else int(start[\"Trip Alternatives Is Good\"])\n",
    "            )\n",
    "            data[\"user_group_name\"] = start[\"User Group Name\"]\n",
    "\n",
    "        if \"start_location\" not in data:\n",
    "            continue\n",
    "        # Add the data to the corresponding group\n",
    "        if t[\"User Group Name\"] == \"MyTravels_Group_A\" or t[\"User Group Name\"] == \"MyTravels_Group_A_extended\":\n",
    "            data[\"group\"] = 1\n",
    "        elif t[\"User Group Name\"] == \"MyTravels_Group_B\" or t[\"User Group Name\"] == \"MyTravels_Group_B_extended\":\n",
    "            data[\"group\"] = 0\n",
    "        trips_data.append(data)\n",
    "\n",
    "    # only consider trips since 24.07\n",
    "    trips_data = pd.DataFrame(trips_data)\n",
    "    trips_data[\"date\"] = pd.to_datetime(trips_data[\"date\"], format=\"%Y-%m-%d\")\n",
    "    trips_data.dropna(subset=[\"start_time\", \"end_time\"], inplace=True)\n",
    "    trips_data[\"start_time\"] = pd.to_datetime(trips_data[\"start_time\"])\n",
    "    trips_data[\"end_time\"] = pd.to_datetime(trips_data[\"end_time\"])\n",
    "    trips_data = trips_data[\n",
    "        (pd.Timestamp(\"2024-07-24\") <= trips_data[\"date\"]) & \n",
    "        (pd.Timestamp(\"2024-12-20\") >= trips_data[\"date\"])\n",
    "    ]\n",
    "    return trips_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = transform_origin_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.to_csv(f\"{DATA_FOLDER}/0.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate stop times between trips\n",
    "def calculate_stop_times(df):\n",
    "    \"\"\"\n",
    "    Calculate the stop times between the end of one trip and the start of the next trip \n",
    "    for the same vehicle on the same day.\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=[\"vehicle_id\", \"date\", \"start_time\"])\n",
    "    df[\"prev_end_time\"] = df.groupby([\"vehicle_id\", \"date\"])[\"end_time\"].shift(1)\n",
    "    # Calculate stop times in minutes\n",
    "    df[\"stop_time\"] = (df[\"start_time\"] - df[\"prev_end_time\"]).dt.total_seconds() / 60  # Convert to minutes\n",
    "    df[\"stop_time\"] = df.apply(lambda r: r[\"stop_time\"] if r[\"stop_time\"] > 0 else 0, axis=1)\n",
    "    # Set stop time to NaN for the first trip of the day\n",
    "    df[\"stop_time\"] = df.apply(lambda r: 0 if pd.isna(r[\"stop_time\"]) else r[\"stop_time\"], axis=1)\n",
    "    df = df.drop(columns=\"prev_end_time\")\n",
    "    return df\n",
    "\n",
    "# Remove outliers based on quantiles\n",
    "def remove_outliers(df):\n",
    "    \"\"\"\n",
    "    Remove outliers based on the 1st and 99th percentiles.\n",
    "    \"\"\"\n",
    "    stop_time_col, distance_col = \"stop_time\", \"distance\"\n",
    "    stop_times = np.percentile(df[stop_time_col], [0, 99])\n",
    "    distances = np.percentile(df[distance_col], [0, 99])\n",
    "    filtered_df = df[\n",
    "        (df[stop_time_col] >= stop_times[0]) & \n",
    "        (df[stop_time_col] <= stop_times[1]) &\n",
    "        (df[distance_col] >= distances[0]) &\n",
    "        (df[distance_col] <= distances[1])\n",
    "    ]\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df_0.copy()\n",
    "df_1 = calculate_stop_times(df_0)\n",
    "df_1 = remove_outliers(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(f\"{DATA_FOLDER}/1.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clustering_analysis(df, col, n_clusters=3):\n",
    "    \"\"\"\n",
    "    Perform clustering analysis on stop time and sum of distances.\n",
    "    \"\"\"\n",
    "    # Use stop_time and sum_distance for clustering\n",
    "    data = df[[col]].dropna()\n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    data[\"cluster\"] = kmeans.fit_predict(data)\n",
    "    # Display cluster centers\n",
    "    for i, center in enumerate(kmeans.cluster_centers_):\n",
    "        cluster_data = data[data[\"cluster\"] == i]\n",
    "        # Calculate standard deviation of stop_time and sum_distance for each cluster\n",
    "        avg = center[0]\n",
    "        std = cluster_data[col].std()\n",
    "        print(f\"[{col}]: Mean {avg}, Standard Deviation {std}, upper bound = {avg + std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_time = clustering_analysis(df_1, \"stop_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_trips(df):\n",
    "    df[\"trip_id\"] = -1  # -1 indicates not assigned to any group\n",
    "\n",
    "    # Label which trips should be merged\n",
    "    for _, group in df.groupby([\"vehicle_id\", \"date\"]):\n",
    "        current_trip_id = 0  # Group identifier within this vehicle_id and date group\n",
    "        previous_row = None\n",
    "        for idx, row in group.iterrows():\n",
    "            if previous_row is None:  # First row starts a new group\n",
    "                df.at[idx, \"trip_id\"] = current_trip_id\n",
    "            else:\n",
    "                # Check if current row should be in the same group\n",
    "                if row[\"stop_time\"] <= stop_time:\n",
    "                    df.at[idx, \"trip_id\"] = current_trip_id\n",
    "                else:\n",
    "                    # Start a new group\n",
    "                    current_trip_id += 1\n",
    "                    df.at[idx, \"trip_id\"] = current_trip_id\n",
    "            previous_row = row  # Update the previous row reference\n",
    "\n",
    "    # Merge trips\n",
    "    merged_trips = df.groupby([\"vehicle_id\", \"date\", \"trip_id\"]).agg({\n",
    "        \"efficient_mode\": \"mean\",\n",
    "        \"vehicle_type\": \"first\",\n",
    "        \"electric_consumption\": \"sum\",\n",
    "        \"fuel_consumption\": \"sum\",\n",
    "        \"speed\": \"mean\",\n",
    "        \"distance\": \"sum\",\n",
    "        \"weekday\": \"first\",\n",
    "        \"app_open_count\": \"first\",\n",
    "        \"start_time\": \"first\",\n",
    "        \"end_time\": \"last\",\n",
    "        \"start_location\": \"first\",\n",
    "        \"end_location\": \"last\",\n",
    "        \"start_lat\": \"first\",\n",
    "        \"start_lng\": \"first\",\n",
    "        \"end_lng\": \"last\",\n",
    "        \"end_lat\": \"last\",\n",
    "        \"distance_bicycle\": \"sum\",\n",
    "        \"distance_diff_bicycle\": \"sum\",\n",
    "        \"time_diff_bicycle\": \"sum\",\n",
    "        \"is_bicycle_good_alternative\": \"mean\",\n",
    "        \"distance_pedestrian\": \"sum\",\n",
    "        \"distance_diff_pedestrian\": \"sum\",\n",
    "        \"time_diff_pedestrian\": \"sum\",\n",
    "        \"is_pedestrian_good_alternative\": \"mean\",\n",
    "        \"distance_publicTransport\": \"sum\",\n",
    "        \"distance_diff_publicTransport\": \"sum\",\n",
    "        \"time_diff_publicTransport\": \"sum\",\n",
    "        \"is_publicTransport_good_alternative\": \"mean\",\n",
    "        \"group\": \"first\",\n",
    "        \"stop_time\": \"sum\",\n",
    "    }).reset_index()\n",
    "    merged_trips.drop(columns=[\"trip_id\"], inplace=True)\n",
    "    merged_trips[\"alternative_score\"] = (\n",
    "        merged_trips[\"is_bicycle_good_alternative\"] + #bicycle_score\n",
    "        merged_trips[\"is_pedestrian_good_alternative\"] +\n",
    "        merged_trips[\"is_publicTransport_good_alternative\"]\n",
    "    )\n",
    "    # remove unmergable parking trips\n",
    "    merged_trips = merged_trips[merged_trips[\"distance\"] >= 0.8]\n",
    "    return merge_trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1.copy()\n",
    "df_2 = merge_trips(df_2)\n",
    "df_2[\"phase\"] = df_2.apply(\n",
    "    lambda r: (\n",
    "        (\n",
    "            1 if r[\"date\"] >= pd.Timestamp(\"2024-09-24\") else 0\n",
    "        ) if r[\"group\"] == 1 else (\n",
    "            1 if r[\"date\"] >= pd.Timestamp(\"2024-10-24\") else 0\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(f\"{DATA_FOLDER}/2.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_app_open_count():\n",
    "    def calculate_count(filename):\n",
    "        df = pd.read_csv(f\"C:/Users/Q672355/OneDrive/MA/Daten/{filename}.csv\", sep=\",\", encoding=\"utf-8\")\n",
    "        df = df.dropna(subset=[\"Vehicle ID\", \"Trip Segments Timestamp\"])\n",
    "        df[\"Trip Segments Timestamp\"] = df[\"Trip Segments Timestamp\"].apply(lambda v: v.split(\" \")[0])\n",
    "        df = df.groupby(\"Vehicle ID\").agg(\n",
    "            min_timestamp=(\"Trip Segments Timestamp\", \"min\"),\n",
    "            max_timestamp=(\"Trip Segments Timestamp\", \"max\"),\n",
    "            open_count=(\"User App Open Count\", \"first\"),\n",
    "        ).reset_index()\n",
    "        df[\"open_count\"] = df[\"open_count\"].apply(lambda v: 0 if pd.isna(v) else int(v))\n",
    "        df[\"Vehicle ID\"] = df[\"Vehicle ID\"].apply(lambda v: int(v))\n",
    "        return df.set_index(\"Vehicle ID\").to_dict(orient=\"index\")\n",
    "\n",
    "    # set activeness via app open. active -> open at least once a week on avg\n",
    "    open_count_2110 = calculate_count(\"2024-10-21_detailed_query_alternatives_segments\")\n",
    "    open_count_2212 = calculate_count(\"2024-12-22_detailed_query_alternatives_segments\")\n",
    "\n",
    "    active_vehicle_ids = []\n",
    "    open_count_vids = {}\n",
    "    for vehicle_id, data_2212 in open_count_2212.items():\n",
    "        if vehicle_id in open_count_2110:\n",
    "            data_2110 = open_count_2110[vehicle_id]\n",
    "            open_count = data_2212[\"open_count\"] - data_2110[\"open_count\"]\n",
    "            ts1 = pd.Timestamp(data_2110[\"max_timestamp\"])\n",
    "            ts2 = pd.Timestamp(data_2212[\"max_timestamp\"])\n",
    "        else:\n",
    "            open_count = data_2212[\"open_count\"]\n",
    "            ts1 = pd.Timestamp(data_2212[\"min_timestamp\"])\n",
    "            ts2 = pd.Timestamp(data_2212[\"max_timestamp\"])\n",
    "        weeks = ((ts2 - ts1).days)//7\n",
    "        if open_count >= weeks:\n",
    "            active_vehicle_ids.append(int(vehicle_id))\n",
    "        open_count_vids[int(vehicle_id)] = open_count\n",
    "    return open_count_vids, active_vehicle_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_count_vids, active_vehicle_ids = get_app_open_count()\n",
    "df_3 = df_2.copy()\n",
    "df_3[\"active\"] = df_3.apply(lambda r: 1 if r[\"vehicle_id\"] in active_vehicle_ids else 0, axis=1)\n",
    "df_3[\"app_open_count\"] = df_3.apply(lambda r: open_count_vids[r[\"vehicle_id\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3.to_csv(f\"{DATA_FOLDER}/3.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex to match 4-digit postcode\n",
    "def get_postcode(df):\n",
    "    pattern = r\"\\b\\d{4}\\b\"\n",
    "    fake_postcode = -1\n",
    "\n",
    "    def get_postcode(location):\n",
    "        try:\n",
    "            return int(re.findall(pattern, location)[-1])\n",
    "        except:\n",
    "            nonlocal fake_postcode\n",
    "            fake_postcode -= 1\n",
    "            return fake_postcode\n",
    "\n",
    "    df[\"postcode\"] = df[\"start_location\"].apply(get_postcode)\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_weather_category(df):\n",
    "    # Define thresholds\n",
    "    SUNSHINE_THRESHOLD = 11 # hours of sunshine to consider sunny\n",
    "    PRECIP_THRESHOLD = 1  # precipitation threshold in mm/day\n",
    "\n",
    "    # Function to assign season based on month\n",
    "    def assign_season(date):\n",
    "        month = date.month\n",
    "        if month in [11, 12]:  # Winter includes November and December\n",
    "            return \"Winter\"\n",
    "        elif month in [9, 10]:  # Autumn includes September and October\n",
    "            return \"Autumn\"\n",
    "        elif month in [7, 8]:  # Summer includes July and August\n",
    "            return \"Summer\"\n",
    "\n",
    "    df[\"season\"] = df[\"date\"].apply(assign_season)\n",
    "\n",
    "    # Ensure \"season\" column is properly categorized\n",
    "    df[\"season\"] = pd.Categorical(df[\"season\"], categories=[\"Summer\", \"Autumn\", \"Winter\"], ordered=True)\n",
    "\n",
    "    # Function to categorize weather with the additional condition for winter\n",
    "    def categorize_weather(row):\n",
    "        temp = row[\"apparent_temperature_mean\"]\n",
    "        precip = row[\"precipitation_sum\"]\n",
    "        sunshine = row[\"sunshine_duration\"]\n",
    "        if precip > PRECIP_THRESHOLD: # > 1 mm/day\n",
    "            return \"rainy\"\n",
    "        elif 13 <= temp <= 29: \n",
    "            return \"sunny\"\n",
    "        #elif 0 <= temp < 13 and sunshine >= SUNSHINE_THRESHOLD: # varing between 1-12h/day\n",
    "            #return \"sunny\"\n",
    "        return \"unfavorable\"\n",
    "\n",
    "    # Apply the updated categorization function\n",
    "    df[\"weather_category\"] = df.apply(categorize_weather, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4 = df_3.copy()\n",
    "df_4 = get_postcode(df_3)\n",
    "weather_df = pd.read_csv(f\"{DATA_FOLDER}/region_weather.csv\")\n",
    "df_4 = pd.merge(df_4, weather_df, on=[\"postcode\", \"date\"], how=\"left\")\n",
    "df_4 = get_weather_category(df_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_4.to_csv(f\"{DATA_FOLDER}/4.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_driver_types(df):\n",
    "    df = df[df[\"date\"] < pd.Timestamp(\"2024-09-24\")]\n",
    "    \"\"\"Add columns for trip type based on distance.\"\"\"\n",
    "    df[\"short_trip\"] = df[\"distance\"].apply(lambda x: 1 if x <= 5 else 0)\n",
    "    df[\"medium_trip\"] = df[\"distance\"].apply(lambda x: 1 if 5 < x <= 30 else 0)\n",
    "    df[\"long_trip\"] = df[\"distance\"].apply(lambda x: 1 if x > 30 else 0)\n",
    "    user_trip_data = df.groupby(\"vehicle_id\")[[\"short_trip\", \"medium_trip\", \"long_trip\"]].sum()\n",
    "    user_trip_data_sum = user_trip_data.sum(axis=1)\n",
    "    user_trip_data_normalized = user_trip_data.div(user_trip_data_sum, axis=0).fillna(0)\n",
    "\n",
    "    # Scale the data for clustering\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(user_trip_data_normalized)\n",
    "\n",
    "    # Perform KMeans clustering\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "    user_trip_data_normalized[\"cluster\"] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "    # Map clusters to readable driver types\n",
    "    cluster_names = {0: \"medium_drivers\", 1: \"medium_drivers\", 2: \"short_drivers\"}\n",
    "    user_trip_data_normalized[\"driver_type\"] = user_trip_data_normalized[\"cluster\"].map(cluster_names)\n",
    "\n",
    "    # Reset index for analysis\n",
    "    user_trip_data_normalized = user_trip_data_normalized.reset_index()\n",
    "\n",
    "    # Calculate average trip proportions per cluster\n",
    "    cluster_averages = user_trip_data_normalized.groupby(\"driver_type\")[[\"short_medium_trip\", \"medium_trip\", \"long_trip\"]].mean()\n",
    "\n",
    "    # Normalize cluster averages\n",
    "    cluster_averages_normalized = cluster_averages.div(cluster_averages.sum(axis=1), axis=0)\n",
    "\n",
    "    # Count the number of users in each cluster\n",
    "    cluster_counts = user_trip_data_normalized[\"driver_type\"].value_counts()\n",
    "\n",
    "    # Plot cluster averages\n",
    "    cluster_averages_normalized = cluster_averages_normalized.loc[[\"short_drivers\", \"medium_drivers\", \"long_drivers\"]]\n",
    "    cluster_counts = cluster_counts.loc[[\"short_drivers\", \"medium_drivers\", \"long_drivers\"]]\n",
    "\n",
    "    # Save a CSV with unique vehicle_id and driver_type\n",
    "    unique_driver_types = user_trip_data_normalized[[\"vehicle_id\", \"driver_type\"]].reset_index(drop=True)\n",
    "    return unique_driver_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_driver_types = get_unique_driver_types(df_4)\n",
    "df_5 = df_4.merge(unique_driver_types, on=\"vehicle_id\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_5.to_csv(f\"{DATA_FOLDER}/5.csv\", index=False, header=True, sep=\",\", encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_usage(df):\n",
    "    df[\"trip\"] = 1\n",
    "    df[\"vshort_trip\"] = df.apply(lambda r: 1 if r[\"distance\"] <= 1 else 0, axis=1)\n",
    "    df[\"short_trip\"] = df.apply(lambda r: 1 if 1 < r[\"distance\"] <= 5 else 0, axis=1)\n",
    "    df[\"medium_trip\"] = df.apply(lambda r: 1 if 5 < r[\"distance\"] <= 30 else 0, axis=1)\n",
    "    df[\"long_trip\"] = df.apply(lambda r: 1 if 30 < r[\"distance\"] else 0, axis=1)\n",
    "    trip_types = [\"trip\", \"vshort_trip\", \"short_trip\", \"medium_trip\", \"long_trip\"]\n",
    "    car_usage = None\n",
    "    for trip_type in trip_types:\n",
    "        agg = df.groupby([\"vehicle_id\", \"phase\"]).agg(\n",
    "            num_trips=(trip_type, \"sum\"),\n",
    "            period=(\"date\", lambda d: ((max(d) - min(d)).days + 1)/7),\n",
    "        ).reset_index()\n",
    "        agg[f\"weekly_{trip_type}\"] = agg[\"num_trips\"] / agg[\"period\"]\n",
    "        agg = agg[[\"vehicle_id\", \"phase\", f\"weekly_{trip_type}\", \"periods\"]]\n",
    "        if car_usage is None:\n",
    "            car_usage = agg\n",
    "        else:\n",
    "            car_usage = car_usage.merge(agg[[\"vehicle_id\", \"phase\", f\"weekly_{trip_type}\"]], \n",
    "                                        on=[\"vehicle_id\", \"phase\"], \n",
    "                                        how=\"left\")\n",
    "    car_usage = car_usage[car_usage[\"period\"] >= 1]\n",
    "    df = df.merge(car_usage, on=[\"vehicle_id\", \"phase\"], how=\"left\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel_test_df_2 = df_1.copy()\n",
    "parallel_test_df_2 = merge_trips(parallel_test_df_2)\n",
    "parallel_test_df_2[\"phase\"] = parallel_test_df_2.apply(\n",
    "    lambda r: (\n",
    "        (\n",
    "            1 if r[\"date\"] >= pd.Timestamp(\"2024-09-24\") else 0\n",
    "        ) if r[\"group\"] == 1 else (\n",
    "            1 if r[\"date\"] >= pd.Timestamp(\"2024-10-24\") else 0\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "parallel_test_df_3 = parallel_test_df_2.copy()\n",
    "parallel_test_df_3[\"active\"] = parallel_test_df_3.apply(lambda r: 1 if r[\"vehicle_id\"] in active_vehicle_ids else 0, axis=1)\n",
    "parallel_test_df_3[\"app_open_count\"] = parallel_test_df_3.apply(lambda r: open_count_vids[r[\"vehicle_id\"]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathers = [\"sunny\", \"rainy\", \"unfavorable\"]\n",
    "week_types = [\n",
    "    (\"weekday\", [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]), \n",
    "    (\"weekend\", [\"Saturday\", \"Sunday\"])\n",
    "]\n",
    "df_6_map = {}\n",
    "for weather in weathers:\n",
    "    df_6 = df_5.copy()\n",
    "    df_6 = df_6[(df_6[\"weather_category\"] == weather)]\n",
    "    df_6_map[weather] = {}\n",
    "    for week_type, weekdays in week_types:\n",
    "        df_6 = df_6[df_6[\"weekday\"].isin(weekdays)]\n",
    "        df_6_map[weather][week_type] = get_car_usage(df_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_survey_info():    \n",
    "    df = pd.read_excel(\n",
    "        r\"C:\\Users\\Q672355\\OneDrive\\MA\\Daten\\Umfragedaten_Pre-Survey_Distances.xlsx\"\n",
    "    )\n",
    "    df = df[[\n",
    "        \"Tabelle1.Vehicle.ID\",\n",
    "        \"Tabelle1.User.Group.Name\", \n",
    "        \"What is your age?\",\n",
    "        \"What gender do you identify yourself with?\",\n",
    "        \"What is the composition of your household?\",\n",
    "        \"What ownership characteristic best describes your situation?\",\n",
    "        \"What type of BMW do you drive?\",\n",
    "        \"What describes your current situation best?\",\n",
    "        \"Approximately, what is your yearly mileage?\",\n",
    "        \"How often per week do you use the following modes of transportation? - Car\",\n",
    "        \"How often per week do you use the following modes of transportation? - Public Transport\",\n",
    "        \"How often per week do you use the following modes of transportation? - Bike / E-bike\",\n",
    "        \"How often per week do you use the following modes of transportation? -  Scooter / motorbike\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Shorter than 10 km\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Between 10-50 km\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Longer than 50 km\"\n",
    "    ]]\n",
    "    df.rename(columns={\n",
    "        \"Tabelle1.Vehicle.ID\": \"vehicle_id\",\n",
    "        \"Tabelle1.User.Group.Name\": \"group_name\", \n",
    "        \"What is your age?\": \"age\", \n",
    "        \"What gender do you identify yourself with?\": \"gender\",\n",
    "        \"What is the composition of your household?\": \"family_status\",\n",
    "        \"What type of BMW do you drive?\": \"car_type\",\n",
    "        \"What ownership characteristic best describes your situation?\": \"car_ownership\",\n",
    "        \"What describes your current situation best?\": \"situation\",\n",
    "        \"Approximately, what is your yearly mileage?\": \"yearly_mileage\",\n",
    "        \"How often per week do you use the following modes of transportation? - Car\": \"usage_frequency\",\n",
    "        \"How often per week do you use the following modes of transportation? - Public Transport\": \"public_transport_frequency\",\n",
    "        \"How often per week do you use the following modes of transportation? - Bike / E-bike\": \"e_bike_frequency\",\n",
    "        \"How often per week do you use the following modes of transportation? -  Scooter / motorbike\": \"scooter_motorbike_frequency\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Shorter than 10 km\": \"less_than_10km_frequency\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Between 10-50 km\": \"btw_10_50_km_frequency\",\n",
    "        \"Approximately, how many times a week do you use the car for the following trip lengths?  - Longer than 50 km\": \"longer_than_50_km_frequency\",\n",
    "    }, inplace=True)\n",
    "\n",
    "    age_mapping = {\n",
    "        \"18-24\": \"young\",\n",
    "        \"25-34\": \"young\",\n",
    "        \"35-44\": \"middle\",\n",
    "        \"45-54\": \"middle\",\n",
    "        \"45 - 54\": \"middle\", \n",
    "        \"55 - 64\": \"old\",\n",
    "        \"55-64\": \"old\",  \n",
    "        \"65 of ouder\": \"old\",\n",
    "        \"Older than 65\": \"old\",\n",
    "    }\n",
    "    \"\"\"\n",
    "    age_mapping = {\n",
    "        \"18-24\": 20,\n",
    "        \"25-34\": 30,\n",
    "        \"35-44\": 40,\n",
    "        \"45-54\": 50,\n",
    "        \"45 - 54\": 50, \n",
    "        \"55 - 64\": 60,\n",
    "        \"55-64\": 60,  \n",
    "        \"65 of ouder\": 70,\n",
    "        \"Older than 65\": 70,\n",
    "    }\n",
    "    \"\"\"\n",
    "    car_ownership_mapping = {\n",
    "        \"Private lease\": \"private_lease\",\n",
    "        \"Zakelijke lease\": \"company_lease\",\n",
    "        \"Privé eigenaar\": \"private_own\",\n",
    "        \"Zakelijke eigenaar\": \"company_own\",\n",
    "    }\n",
    "\n",
    "    car_type_mapping = {\n",
    "        \"Benzine\": \"Benzine\",\n",
    "        \"Diesel\": \"Diesel\",\n",
    "        \"Plug-in Hybride\": \"PHEV\",\n",
    "        \"Volledig elektrisch\": \"EL\",\n",
    "    }\n",
    "\n",
    "    gender_mapping = {\n",
    "        \"Man\": \"man\",\n",
    "        \"Vrouw\": \"woman\",\n",
    "        \"Ik geef liever geen antwoord\": \"woman\",\n",
    "    }\n",
    "    family_status_mapping = {\n",
    "        \"Anders, namelijk\": \"without_children\",\n",
    "        \"Eenpersoons huishouden\": \"single\",\n",
    "        \"Andere vormen van samenwonen (kamergenoten, huisgenoten, etc.)\": \"without_children\",\n",
    "        \"Samenwonend zonder thuiswondende kinderen\": \"without_children\",\n",
    "        \"Samenwonend met thuiswonende kinderen\": \"with_children\",\n",
    "        \"Alleenstaande ouder met kinderen\": \"with_children\",\n",
    "        \"Samenwondend met andere familieleden\": \"extended_family\",\n",
    "    }\n",
    "\n",
    "    situation_mapping = {\n",
    "        \"Niet aanwezig in de arbeidspopulatie\": \"unemployed\",\n",
    "        \"Student\": \"unemployed\",\n",
    "        \"Werkloos\": \"unemployed\",\n",
    "        \"Anders, namelijk\": \"unemployed\",\n",
    "        \"Werkzaam (full-time of part-time)\": \"employed\",\n",
    "        \"Zelfstandig werknemer\": \"employed\"\n",
    "    }\n",
    "\n",
    "    yearly_mileage_mapping = {\n",
    "        \"Minder dan 5.000 km\": \"Less than 5000 km\",\n",
    "        \"Tussen 5.000 km en 10.000 km\": \"5000-10000 km\",\n",
    "        \"Tussen 10.000 km en 25.000 km\": \"10000-25000 km\",\n",
    "        \"Tussen 25.000 km en 50.000 km\": \"25000-50000 km\",\n",
    "        \"Meer dan 50.000 km\": \"More than 50000 km\",\n",
    "    }\n",
    "\n",
    "    usage_frequency_mapping = {\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    public_transport_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    e_bike_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    scooter_motorbike_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    length_less_10_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    length_10_50_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "    length_than_50_frequency_mapping = {\n",
    "        \"Nooit\": \"never\",\n",
    "        \"1-3 dagen\": \"sometimes\",\n",
    "        \"3-5 dagen\": \"often\",\n",
    "        \"Meer dan 5 dagen\": \"usual\",\n",
    "    }\n",
    "\n",
    "\n",
    "    def mapping(row):\n",
    "        row[\"age\"] = age_mapping[row[\"age\"]]\n",
    "        row[\"gender\"] = gender_mapping[row[\"gender\"]]\n",
    "        row[\"family_status\"] = family_status_mapping[row[\"family_status\"]]\n",
    "        row[\"car_ownership\"] = car_ownership_mapping[row[\"car_ownership\"]]\n",
    "        row[\"car_type\"] = car_type_mapping[row[\"car_type\"]]\n",
    "        row[\"situation\"] = situation_mapping[row[\"situation\"]]\n",
    "        row[\"yearly_mileage\"] = yearly_mileage_mapping[row[\"yearly_mileage\"]]\n",
    "        row[\"usage_frequency\"] = usage_frequency_mapping[row[\"usage_frequency\"]]\n",
    "        row[\"public_transport_frequency\"] = public_transport_frequency_mapping[row[\"public_transport_frequency\"]]\n",
    "        row[\"e_bike_frequency\"] = e_bike_frequency_mapping[row[\"e_bike_frequency\"]]\n",
    "        row[\"scooter_motorbike_frequency\"] = scooter_motorbike_frequency_mapping[row[\"scooter_motorbike_frequency\"]]\n",
    "        row[\"less_than_10km_frequency\"] = length_less_10_frequency_mapping[row[\"less_than_10km_frequency\"]]\n",
    "        row[\"btw_10_50_km_frequency\"] = length_10_50_frequency_mapping[row[\"btw_10_50_km_frequency\"]]\n",
    "        row[\"longer_than_50_km_frequency\"] = length_than_50_frequency_mapping[row[\"longer_than_50_km_frequency\"]]\n",
    "        return row\n",
    "    survey_info = df.apply(mapping, axis=1)\n",
    "    return survey_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_info = get_survey_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_effect_model(df, outcome_var, group_col, phase_col):\n",
    "    \"\"\"\n",
    "    Fit a mixed-effects model with specified fixed and random effects.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - outcome_var: Dependent variable (e.g., \"weekly_trip\").\n",
    "    - group_col: Column indicating treatment group (e.g., \"active\").\n",
    "    - phase_col: Column indicating the treatment period (e.g., \"phase\").\n",
    "    \n",
    "    Returns:\n",
    "    - Fitted model object.\n",
    "    \"\"\"\n",
    "    print(f\"-------------------------------[{outcome_var}]-------------------------------\")\n",
    "    \n",
    "    df[group_col] = df[group_col].astype(\"category\")\n",
    "    df[phase_col] = df[phase_col].astype(\"category\")\n",
    "    phase_counts = df.groupby(\"vehicle_id\")[\"phase\"].nunique()\n",
    "    selected_vids = set(phase_counts[phase_counts == 2].index.tolist())\n",
    "    df = df[df[\"vehicle_id\"].isin(selected_vids)]\n",
    "    # Model formula: interaction between phase and group\n",
    "    formula = f\"{outcome_var} ~ C({phase_col}, Treatment(0)) * C({group_col}, Treatment(0))\"\n",
    "\n",
    "    # Fit mixed-effects model\n",
    "    model = smf.mixedlm(\n",
    "        formula=formula,\n",
    "        data=df,\n",
    "        groups=df[\"vehicle_id\"],  # Random intercept\n",
    "        re_formula=\"~C(phase, Treatment(0))\"  # Random slope\n",
    "    ).fit()\n",
    "\n",
    "    # Compute R² values\n",
    "    fixed_effects_variance = np.var(model.fittedvalues)\n",
    "    residual_variance = model.scale\n",
    "    random_effects_variance = sum(np.var(v) for v in model.random_effects.values()) if model.random_effects else 0\n",
    "\n",
    "    marginal_r2 = fixed_effects_variance / (fixed_effects_variance + random_effects_variance + residual_variance)\n",
    "    conditional_r2 = (fixed_effects_variance + random_effects_variance) / (fixed_effects_variance + random_effects_variance + residual_variance)\n",
    "\n",
    "    print(f\"Marginal R² (fixed effects only): {marginal_r2:.4f}\")\n",
    "    print(f\"Conditional R² (fixed + random effects): {conditional_r2:.4f}\")\n",
    "    print(model.cov_re)  # Shows variance of random intercept & slope\n",
    "\n",
    "    # Count number of unique vehicles per group\n",
    "    count_phase_1 = df[df[group_col] == 1][\"vehicle_id\"].nunique()\n",
    "    count_phase_0 = df[df[group_col] == 0][\"vehicle_id\"].nunique()\n",
    "    total_count = count_phase_1 + count_phase_0\n",
    "    percentage_difference = abs(count_phase_1 - count_phase_0) / total_count * 100\n",
    "\n",
    "    print(f\"Number of unique vehicle_id where active == 1 (active): {count_phase_1}\")\n",
    "    print(f\"Number of unique vehicle_id where active == 0 (inactive): {count_phase_0}\")\n",
    "    print(f\"Percentage difference: {percentage_difference:.3f}%\")\n",
    "\n",
    "    # # Extract DiD effect and p-value\n",
    "    # interaction_term = f\"C({phase_col}, Treatment(0))[T.1]:C({group_col}, Treatment(0))[T.1]\"\n",
    "    # did_effect = model.params.get(interaction_term, 0)\n",
    "    # p_value = model.pvalues.get(interaction_term, 1)\n",
    "\n",
    "    # se_did = model.bse.get(interaction_term, 0)\n",
    "    # ci_lower, ci_upper = model.conf_int().loc[interaction_term]\n",
    "    return model\n",
    "\n",
    "\n",
    "def mixed_effect_model_moderating(df, outcome_var, group_col, phase_col, group_cat, moderating_effects=None):\n",
    "    \"\"\"\n",
    "    Fit a mixed-effects model with specified moderating and random effects.\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame containing the data.\n",
    "    - outcome_var: Dependent variable (e.g., \"outcome\").\n",
    "    - group_col: Column indicating treatment group (e.g., \"group\").\n",
    "    - phase_col: Column indicating the treatment period (e.g., \"phase\").\n",
    "    - random_effects: Dictionary of random effects in vc_formula format.\n",
    "    \n",
    "    Returns:\n",
    "    - Fitted model object.\n",
    "    \"\"\"\n",
    "    print(f\"-------------------------------[{outcome_var}]-------------------------------\")\n",
    "    # Ensure categorical variables are treated as such\n",
    "    phase_counts = df.groupby(\"vehicle_id\")[\"phase\"].nunique()\n",
    "    selected_vids = set(phase_counts[phase_counts == 2].index.tolist())\n",
    "    df = df[df[\"vehicle_id\"].isin(selected_vids)]\n",
    "\n",
    "    formula = f\"{outcome_var} ~ C({phase_col}, Treatment(0)) * C({group_col}, Treatment(0))\"\n",
    "    df.loc[:, group_col] = df[group_col].astype(\"category\")\n",
    "    df.loc[:, phase_col] = df[phase_col].astype(\"category\")\n",
    "    if moderating_effects is not None:\n",
    "        for moderating_effect, reference in moderating_effects:\n",
    "            if moderating_effect != \"app_open_count_type\":\n",
    "                df.loc[:, moderating_effect] = df[moderating_effect].astype(\"category\")\n",
    "                # formula += f\" + C({moderating_effect}, Treatment('{reference}')) * C({phase_col}, Treatment(0))\"\n",
    "                if isinstance(reference, str):\n",
    "                    formula += f\" + C({moderating_effect}, Treatment('{reference}')) * C({phase_col}, Treatment(0))\"\n",
    "                elif isinstance(reference, (int, float)):\n",
    "                    formula += f\" + C({moderating_effect}, Treatment({reference}))  * C({phase_col}, Treatment(0))\"\n",
    "            else:\n",
    "                formula += f\" + C({moderating_effect}, Treatment('{reference}'))  * C({phase_col}, Treatment(0))\"\n",
    "    # moderating effects formula\n",
    "    # Variance components formula\n",
    "    re_formula = f\" ~C({phase_col}, Treatment(0))\" # Random effects model (random intercept for group = \"vehicle_id\")\n",
    " #random_cat: specific factor varing across individuals  (work not value does not change per individual...)\n",
    "    # Fit the mixed-effects model\n",
    "    model = smf.mixedlm(\n",
    "        formula=formula,\n",
    "        data=df,\n",
    "        groups=df[group_cat], # Random effects account for variability across groups (in your case, different vehicles). These represent the individual deviations from the moderating effects.\n",
    "        re_formula=re_formula,  # Random effects for variables\n",
    "    ).fit()\n",
    "    # Display the models\n",
    "    print(f\"Covariance matrix of random effects: {model.cov_re}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_did(df, outcome_var, group_col, phase_col, category):\n",
    "    \"\"\"\n",
    "    Plot the DiD results with error bars and annotations.\n",
    "    \"\"\"\n",
    "    # Run model\n",
    "    model, did_effect, p_value, se_did, _, _ = mixed_effect_model(df, outcome_var, group_col, phase_col)\n",
    "\n",
    "    # Generate model-based predictions\n",
    "    pred_data = df.copy()\n",
    "    pred_data[\"prediction\"] = model.predict(pred_data)\n",
    "\n",
    "    # Compute model-based means and standard errors\n",
    "    summary_model = pred_data.groupby([phase_col, group_col])[\"prediction\"].agg([\"mean\", \"sem\"]).reset_index()\n",
    "    summary_model[phase_col] = summary_model[phase_col].map({0: \"Pre Intervention\", 1: \"Post Intervention\"})\n",
    "    summary_model[group_col] = summary_model[group_col].map({0: \"Inactive\", 1: \"Active\"})\n",
    "\n",
    "    # Extract model-based values\n",
    "    means = summary_model.pivot(index=phase_col, columns=group_col, values=\"mean\")\n",
    "    errors = summary_model.pivot(index=phase_col, columns=group_col, values=\"sem\")\n",
    "\n",
    "    # Find vehicles that exist in both phases\n",
    "    vehicles_in_both_phases = df.groupby(\"vehicle_id\")[phase_col].nunique()\n",
    "    valid_vehicles = vehicles_in_both_phases[vehicles_in_both_phases == 2].index\n",
    "\n",
    "    # Count unique vehicle IDs per group (ensuring they exist in both phases)\n",
    "    filtered_df = df[df[\"vehicle_id\"].isin(valid_vehicles)]\n",
    "    counts = filtered_df.groupby(group_col)[\"vehicle_id\"].nunique()\n",
    "\n",
    "    # Extract adjusted values\n",
    "    active_before, active_after = means.loc[\"Pre Intervention\", \"Active\"], means.loc[\"Post Intervention\", \"Active\"]\n",
    "    inactive_before, inactive_after = means.loc[\"Pre Intervention\", \"Inactive\"], means.loc[\"Post Intervention\", \"Inactive\"]\n",
    "\n",
    "    # Compute adjusted within-group changes\n",
    "    change_active = active_after - active_before\n",
    "    change_inactive = inactive_after - inactive_before\n",
    "\n",
    "\n",
    "    # Significance marker\n",
    "    significance = \"\"\n",
    "    if p_value < 0.01:\n",
    "        significance = \"(strong evidence)\"\n",
    "    elif p_value < 0.05:\n",
    "        significance = \"(moderate evidence)\"\n",
    "    elif p_value < 0.1:\n",
    "        significance = \"(weak evidence)\"\n",
    "\n",
    "    # Colors\n",
    "    colors = {\"Inactive\": \"steelblue\", \"Active\": \"firebrick\"}\n",
    "\n",
    "    # Plot\n",
    "    _, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.set_xlim(left=-0.5, right=1.3)  # Adjust as needed\n",
    "\n",
    "    ax.axvline(x=0.5, color=\"green\", linestyle=\"dashed\", linewidth=1.5, label=\"Intervention\")\n",
    "\n",
    "    # Scatter points with error bars\n",
    "    # Find vehicles that exist in both phases\n",
    "    vehicles_in_both_phases = df.groupby(\"vehicle_id\")[phase_col].nunique()\n",
    "    valid_vehicles = vehicles_in_both_phases[vehicles_in_both_phases == 2].index\n",
    "\n",
    "    # Filter the dataset to include only these vehicles\n",
    "    filtered_df = df[df[\"vehicle_id\"].isin(valid_vehicles)]\n",
    "\n",
    "    # Count unique vehicle IDs per group (ensuring they exist in both phases)\n",
    "    counts = filtered_df.groupby(group_col)[\"vehicle_id\"].nunique()\n",
    "\n",
    "    for group in [\"Active\", \"Inactive\"]:\n",
    "        # Convert group label to match df[group_col] values (assuming 1 = Active, 0 = Inactive)\n",
    "        group_value = 1 if group == \"Active\" else 0\n",
    "        ax.errorbar(\n",
    "            [\"Pre Intervention\", \"Post Intervention\"],\n",
    "            means[group],\n",
    "            yerr=errors[group],\n",
    "            fmt=\"o\",\n",
    "            color=colors[group],\n",
    "            markersize=6,\n",
    "            capsize=4,\n",
    "            label=f\"{group} (N={int(counts[group_value])})\"\n",
    "        )\n",
    "\n",
    "    # Connect points with lines\n",
    "    ax.plot([\"Pre Intervention\", \"Post Intervention\"], [inactive_before, inactive_after], color=colors[\"Inactive\"], linestyle=\"-\", linewidth=2)\n",
    "    ax.plot([\"Pre Intervention\", \"Post Intervention\"], [active_before, active_after], color=colors[\"Active\"], linestyle=\"-\", linewidth=2)\n",
    "\n",
    "    # Annotations for within-group changes (aligned with vertical brackets)\n",
    "    text_x_offset = 0.08  # Shift text left\n",
    "    bracket_x_offset = 0.02 # Moves the dashed bracket slightly right\n",
    "\n",
    "    # Difference brackets (dashed lines)\n",
    "    ax.plot([1 + bracket_x_offset, 1 + bracket_x_offset], [active_before, active_after], \n",
    "            color=colors[\"Active\"], linestyle=\"--\", linewidth=2)\n",
    "    ax.annotate(f\"{change_active:.3f}\", xy=(1, active_after), \n",
    "                xytext=(1 + text_x_offset, active_before),\n",
    "                ha=\"left\", fontsize=12, color=colors[\"Active\"], fontweight=\"bold\")\n",
    "\n",
    "    ax.plot([1 + bracket_x_offset, 1 + bracket_x_offset], [inactive_before, inactive_after], \n",
    "            color=colors[\"Inactive\"], linestyle=\"--\", linewidth=2)\n",
    "    ax.annotate(f\"{change_inactive:.3f}\", xy=(1, inactive_after), \n",
    "                xytext=(1 + text_x_offset, inactive_before),\n",
    "                ha=\"left\", fontsize=12, color=colors[\"Inactive\"], fontweight=\"bold\")\n",
    "\n",
    "    # Compute y-limits\n",
    "    y_min = min(means.min()) - 1.5\n",
    "    y_max = max(means.max()) + 1.5\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "\n",
    "    # Treatment effect annotation (Δ - Moved Left)\n",
    "    ci_text = f\"Δ = {did_effect:.3f} {significance}\" #(95% CI: [{ci_lower:.3f}, {ci_upper:.3f}])\"\n",
    "    ax.annotate(ci_text, \n",
    "                xy=(1, active_after), \n",
    "                xytext=(0.1, min(means.min()) - 0.5),  \n",
    "                ha=\"left\", fontsize=10, color=\"black\", fontweight=\"bold\",\n",
    "                bbox=dict(facecolor=\"white\", edgecolor=\"black\", boxstyle=\"round,pad=0.3\"))\n",
    "\n",
    "    formatted_outcome_var = outcome_var.replace(\"_\", \" \").title()  # Converts \"weekly_trips\" -> \"Weekly Trips\"\n",
    "\n",
    "    if category in [\"ICE\", \"BEV\", \"PHEV\"]: \n",
    "        formatted_category = category  # Converts \"weekly_trips\" -> \"Weekly Trips\"\n",
    "    else:\n",
    "        formatted_category = category.replace(\"_\", \" \").title()  # Converts \"weekly_trips\" -> \"Weekly Trips\"\n",
    "\n",
    "    ax.set_xticks([0, 0.5, 1])  # Positions for labels\n",
    "    ax.set_xticklabels([\"Pre Intervention\", \"Intervention\", \"Post Intervention\"])\n",
    "    plt.xlabel(\"Phase\", fontsize=12)\n",
    "    plt.ylabel(f\"Average Number of {formatted_outcome_var}s\", fontsize=12)  # More explicit\n",
    "    plt.title(f\"Intervention Effect on {formatted_outcome_var}s - {formatted_category}\", fontsize=12, fontweight=\"bold\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.6)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    print(f\"DiD effect for {outcome_var}: {did_effect:.3f} SE: {se_did} (p={p_value:.3f}) {significance}\")\n",
    "\n",
    "\n",
    "def estimation_on_family_status(df, outcome_var, group_col, phase_col):\n",
    "    df = pd.merge(df, survey_info, how=\"inner\", on=\"vehicle_id\")\n",
    "    \n",
    "    for category in [\"without_children\", \"with_children\"]:  # Renamed to \"category\" for consistency\n",
    "        d = df[df[\"family_status\"] == category].copy()\n",
    "        count_matching = d[d[group_col] == 1][\"vehicle_id\"].count()\n",
    "        \n",
    "        print(f\"Number of vehicle_id matching the category '{category}'': {count_matching}\")\n",
    "        \n",
    "        if len(d) > 2:\n",
    "            print(f\"Within estimation on [family status] {category}\")\n",
    "            \n",
    "            # Unpack the tuple returned by mixed_effect_model\n",
    "            model = mixed_effect_model(\n",
    "                d, outcome_var=outcome_var, group_col=group_col, phase_col=phase_col\n",
    "            )\n",
    "            \n",
    "            # Print model summary correctly\n",
    "            print(model.summary())  \n",
    "\n",
    "            # Plot results\n",
    "            plot_did(d, outcome_var, group_col=group_col, phase_col=phase_col, category=category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_var = \"weekly_trip\"\n",
    "phase_col = \"phase\"\n",
    "group_cat = \"vehicle_id\"\n",
    "for weather, item in df_6_map.items():\n",
    "    for week_type, df_6 in item.items():\n",
    "        for group_col in [\"inactive\", \"active\"]:\n",
    "            print(f\"--------------------------------{weather}[{week_type}]--------------------------------\")\n",
    "            model = mixed_effect_model(\n",
    "                df_6,\n",
    "                outcome_var=outcome_var,\n",
    "                group_col=group_col,\n",
    "                phase_col=phase_col,\n",
    "            )\n",
    "            print(model.summary())\n",
    "            model = mixed_effect_model_moderating(\n",
    "                df_6,\n",
    "                outcome_var=outcome_var,\n",
    "                group_col=group_col,\n",
    "                phase_col=phase_col,\n",
    "                group_cat=group_cat,\n",
    "                moderating_effects=[(\"alt_score_type\", \"low\")]\n",
    "            )\n",
    "            print(model.summary())\n",
    "            estimation_on_family_status(df_6, outcome_var, group_col, phase_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters store\n",
    "parameters = dict()\n",
    "vehicle_type_map = {\n",
    "    \"Fuel Vehicles\": \"ICE\",\n",
    "    \"Electric Vehicles\": \"BEV\",\n",
    "    \"Hybrid Fuel-Only Vehicles\": \"PHEV (Fuel > 0, Electric = 0)\",\n",
    "    \"Hybrid Electric-Only Vehicles\": \"PHEV (Fuel = 0, Electric > 0)\",\n",
    "    \"Hybrid Fuel-Dominated Vehicles\": \"PHEV (Fuel > 0, Electric < 0)\",\n",
    "    \"Hybrid Combined Vehicles\": \"PHEV (Fuel > 0, Electric > 0)\"\n",
    "}\n",
    "\n",
    "# Exponential Regression Function\n",
    "def exponential_model(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "def fit_exponential_model(data, speed_col, consumption_col):\n",
    "    x = data[speed_col].values\n",
    "    y = data[consumption_col].values\n",
    "    if len(x) < 2:\n",
    "        return None  # Not enough data to fit the model\n",
    "    popt, _ = curve_fit(exponential_model, x, y, maxfev=10000)\n",
    "    return popt\n",
    "\n",
    "\n",
    "# Helper function to find the elbow point based on the derivative\n",
    "def find_elbow_point(params, speed_range):\n",
    "    derivative = -params[0] * params[1] * np.exp(-params[1] * speed_range)\n",
    "    elbow_index = np.argmin(np.abs(derivative - np.mean(derivative)))  # Approximation for elbow\n",
    "    elbow_speed = speed_range[elbow_index]\n",
    "    elbow_rate = exponential_model(np.array([elbow_speed]), *params)[0]\n",
    "    return elbow_speed, elbow_rate\n",
    "\n",
    "\n",
    "# Plot Consumption Rate Function\n",
    "def analyze_fuel_consumption(df, speed_col, rate_col, vehicle_type):\n",
    "    if df.empty:\n",
    "        print(f\"No data available for {vehicle_type}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Split data by efficient mode status\n",
    "    df_on = df[df[\"efficient_mode_status\"] == \"On\"]\n",
    "    df_off = df[df[\"efficient_mode_status\"] == \"Off\"]\n",
    "\n",
    "    # Ensure data for both \"On\" and \"Off\" are present\n",
    "    if df_on.empty and df_off.empty:\n",
    "        print(f\"No data for {vehicle_type} in both 'On' and 'Off' modes. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Fit models separately for \"On\" and \"Off\" modes\n",
    "    params_on = fit_exponential_model(df_on, speed_col, rate_col) if not df_on.empty else None\n",
    "    params_off = fit_exponential_model(df_off, speed_col, rate_col) if not df_off.empty else None\n",
    "\n",
    "    parameters[vehicle_type] = {\"On\": list(params_on), \"Off\": list(params_off)}\n",
    "\n",
    "    # Plot the regression and data points\n",
    "    def plot_regression(df_on, df_off, params_on, params_off, vehicle_type, speed_col, rate_col):\n",
    "        # Plot scatter points for \"On\" and \"Off\"\n",
    "        if not df_on.empty:\n",
    "            plt.scatter(df_on[speed_col], df_on[rate_col], color=\"#035970\", alpha=0.5, label=(\"Efficient Mode: On / Off\"))\n",
    "        if not df_off.empty:\n",
    "            plt.scatter(df_off[speed_col], df_off[rate_col], color=\"#035970\", alpha=0.5)\n",
    "\n",
    "        # Define speed range for plotting regression lines\n",
    "        speed_min = min(df_on[speed_col].min(), df_off[speed_col].min())\n",
    "        speed_max = max(df_on[speed_col].max(), df_off[speed_col].max())\n",
    "        speeds = np.linspace(speed_min, speed_max, 1000)\n",
    "\n",
    "        # Plot regression and elbow points for \"On\"\n",
    "        if params_on is not None:\n",
    "            predicted_rate_on = exponential_model(speeds, *params_on)\n",
    "            plt.plot(speeds, predicted_rate_on, color=\"green\", linewidth=2, linestyle=\"dashed\", label=f\"Regression (On)\")\n",
    "            r2_on = r2_score(df_on[rate_col], exponential_model(df_on[speed_col].values, *params_on))\n",
    "            mse_on = np.sqrt(mean_squared_error(df_on[rate_col], exponential_model(df_on[speed_col], *params_on)))\n",
    "\n",
    "            plt.text(0.05, 0.95, f\"On R² = {r2_on:.3f} and MSE = {mse_on:.3f}\", transform=plt.gca().transAxes, fontsize=12, color=\"green\",\n",
    "            verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "            func_text_on = f\"y = {params_on[0]:.3f} * exp(-{params_on[1]:.3f} * x) + {params_on[2]:.3f}\"\n",
    "            plt.text(0.05, 0.90, f\"{func_text_on}\", transform=plt.gca().transAxes, fontsize=12, color=\"green\",\n",
    "                    verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "            \"\"\"\n",
    "            # Find and plot the elbow point for \"On\"\n",
    "            elbow_on_speed, elbow_on_rate = find_elbow_point(params_on, speeds)\n",
    "            plt.scatter(elbow_on_speed, elbow_on_rate, color=\"green\", s=100, label=\"\", zorder=5)\n",
    "            plt.annotate(f\"Elbow Point (On): {elbow_on_speed:.1f} km/h\\nRate: {elbow_on_rate:.3f}\",\n",
    "                         (elbow_on_speed, elbow_on_rate), textcoords=\"offset points\", xytext=(70, -30),\n",
    "                         arrowprops=dict(arrowstyle=\"->\", color=\"green\"),  bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7), fontsize=10, color=\"green\")\n",
    "            \"\"\"\n",
    "        # Plot regression and elbow points for \"Off\"\n",
    "        if params_off is not None:\n",
    "            predicted_rate_off = exponential_model(speeds, *params_off)\n",
    "            plt.plot(speeds, predicted_rate_off, color=\"red\", linewidth=2, linestyle=\"dotted\", label=f\"Regression (Off)\")\n",
    "            r2_off = r2_score(df_off[rate_col], exponential_model(df_off[speed_col].values, *params_off))\n",
    "            mse_off = np.sqrt(mean_squared_error(df_off[rate_col], exponential_model(df_off[speed_col], *params_off)))\n",
    "            plt.text(0.05, 0.85, f\"Off R² = {r2_off:.3f} and MSE = {mse_off:.3f}\", transform=plt.gca().transAxes, fontsize=12, color=\"red\",\n",
    "            verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "            func_text_off = f\"y = {params_off[0]:.3f} * exp(-{params_off[1]:.3f} * x) + {params_off[2]:.3f}\"\n",
    "            plt.text(0.05, 0.80, f\"{func_text_off}\", transform=plt.gca().transAxes, fontsize=12, color=\"red\",\n",
    "                    verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "\n",
    "            # Find and plot the elbow point for \"Off\"\n",
    "           # elbow_off_speed, elbow_off_rate = find_elbow_point(params_off, speeds)\n",
    "            #plt.scatter(elbow_off_speed, elbow_off_rate, color=\"red\", s=100, label=\"\", zorder=5)\n",
    "            #plt.annotate(f\"Elbow Point (Off): {elbow_off_speed:.1f} km/h\\nRate: {elbow_off_rate:.3f}\",\n",
    "                        # (elbow_off_speed, elbow_off_rate), textcoords=\"offset points\", xytext=(30, -10),\n",
    "                        # arrowprops=dict(arrowstyle=\"->\", color=\"red\"), bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7), fontsize=10, color=\"red\")\n",
    "\n",
    "        # Add title and labels\n",
    "        plt.title(f\"Energy Consumption vs. Speed - {vehicle_type_map[vehicle_type]}\", fontsize=12)\n",
    "        plt.xlabel(\"Speed [km/h]\", fontsize=14)\n",
    "        plt.ylabel(\"Energy Consumption [kWh/100km]\", fontsize=14)\n",
    "        plt.grid(True)\n",
    "        plt.legend(loc=\"center right\", fontsize=10, frameon=True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    plot_regression(df_on, df_off, params_on, params_off, vehicle_type, speed_col, rate_col)\n",
    "\n",
    "\n",
    "# Fit and Plot for Hybrid Cases (Combined Mode)\n",
    "def analyze_electric_comsumption(data, temp_threshold, speed_col, consumption_col, vehicle_type):\n",
    "    if data.empty:\n",
    "        print(f\"No data available for {vehicle_type}. Skipping...\")\n",
    "        return\n",
    "\n",
    "    # Split data based on temperature threshold\n",
    "    data_below = data[data[\"temperature_2m_mean\"] < temp_threshold]\n",
    "    data_above = data[data[\"temperature_2m_mean\"] >= temp_threshold]\n",
    "\n",
    "    # Further split based on efficient mode\n",
    "    def split_by_mode(df):\n",
    "        return df[df[\"efficient_mode_status\"] == \"On\"], df[df[\"efficient_mode_status\"] == \"Off\"]\n",
    "\n",
    "    data_below_on, data_below_off = split_by_mode(data_below)\n",
    "    data_above_on, data_above_off = split_by_mode(data_above)\n",
    "\n",
    "    # Fit models\n",
    "    def fit_model(df):\n",
    "        return fit_exponential_model(df, speed_col, consumption_col) if not df.empty else None\n",
    "\n",
    "    params_below_on = fit_model(data_below_on)\n",
    "    params_below_off = fit_model(data_below_off)\n",
    "    params_above_on = fit_model(data_above_on)\n",
    "    params_above_off = fit_model(data_above_off)\n",
    "\n",
    "    parameters[vehicle_type] = {\"On\": dict(), \"Off\": dict()}\n",
    "    parameters[vehicle_type][\"On\"] = {\n",
    "        \"Below\": list(params_below_on),\n",
    "        \"Above\": list(params_above_on),\n",
    "    }\n",
    "    parameters[vehicle_type][\"Off\"] = {\n",
    "        \"Below\": list(params_below_off),\n",
    "        \"Above\": list(params_above_off),\n",
    "    }\n",
    "\n",
    "    # Create subplots\n",
    "    _, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "    def plot_regression(ax, df_on, df_off, params_on, params_off, title):\n",
    "        if df_on.empty and df_off.empty:\n",
    "            ax.set_title(f\"{title} (No Data)\", fontsize=16)\n",
    "            ax.axis(\"off\")\n",
    "            return\n",
    "\n",
    "        # Use the same scatter color for both On and Off data\n",
    "        ax.scatter(df_on[speed_col], df_on[consumption_col], color=\"#035970\", alpha=0.5, label=(\"Efficient Mode: On / Off\"))\n",
    "        ax.scatter(df_off[speed_col], df_off[consumption_col], color=\"#035970\", alpha=0.5)\n",
    "\n",
    "        # Define speed range safely\n",
    "        all_speeds = np.concatenate([df_on[speed_col].values, df_off[speed_col].values]) if not (df_on.empty and df_off.empty) else []\n",
    "        if len(all_speeds) > 0:\n",
    "            speed_min, speed_max = np.min(all_speeds), np.max(all_speeds)\n",
    "            speeds = np.linspace(speed_min, speed_max, 1000)\n",
    "\n",
    "            # Plot regression for \"On\" data\n",
    "            if params_on is not None:\n",
    "                ax.plot(speeds, exponential_model(speeds, *params_on), color=\"green\", linestyle=\"dashed\", linewidth=2, label=\"Regression (On)\")\n",
    "                r2_on = r2_score(df_on[consumption_col], exponential_model(df_on[speed_col], *params_on))\n",
    "                mse_on = np.sqrt(mean_squared_error(df_on[consumption_col], exponential_model(df_on[speed_col], *params_on)))\n",
    "\n",
    "                ax.text(0.05, 0.95, f\"On R² = {r2_on:.3f} and MSE = {mse_on:.3f}\", transform=ax.transAxes, fontsize=12, color=\"green\",\n",
    "                        verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "                # Display function text for On\n",
    "                func_text_on = f\"y = {params_on[0]:.3f} * exp(-{params_on[1]:.3f} * x) + {params_on[2]:.3f}\"\n",
    "                ax.text(0.05, 0.90, func_text_on, transform=ax.transAxes, fontsize=12, color=\"green\", \n",
    "                        verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "\n",
    "            # Plot regression for \"Off\" data\n",
    "            if params_off is not None:\n",
    "                ax.plot(speeds, exponential_model(speeds, *params_off), color=\"red\", linestyle=\"dotted\", linewidth=2, label=\"Regression (Off)\")\n",
    "                r2_off = r2_score(df_off[consumption_col], exponential_model(df_off[speed_col], *params_off))\n",
    "    \n",
    "                mse_off = np.sqrt(mean_squared_error(df_off[consumption_col], exponential_model(df_off[speed_col], *params_off)))\n",
    "\n",
    "                ax.text(0.05, 0.85, f\"Off R² = {r2_off:.3f} and MSE = {mse_off:.3f}\", transform=ax.transAxes, fontsize=12, color=\"red\",\n",
    "                        verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "                # Display function text for Off\n",
    "                func_text_off = f\"y = {params_off[0]:.3f} * exp(-{params_off[1]:.3f} * x) + {params_off[2]:.3f}\"\n",
    "                ax.text(0.05, 0.80, func_text_off, transform=ax.transAxes, fontsize=12, color=\"red\", \n",
    "                        verticalalignment=\"top\", bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7))\n",
    "        \"\"\"\n",
    "        # Find and mark elbow points for both \"On\" and \"Off\" models\n",
    "        if params_on is not None:\n",
    "            elbow_on_speed, elbow_on_rate = find_elbow_point(params_on, speeds)\n",
    "            ax.scatter(elbow_on_speed, elbow_on_rate, color=\"green\", s=100, label=\"\", zorder=5)\n",
    "            ax.annotate(f\"Elbow Point (On): {elbow_on_speed:.1f} km/h\\nRate: {elbow_on_rate:.3f}\",\n",
    "                        (elbow_on_speed, elbow_on_rate), textcoords=\"offset points\", xytext=(80, -40),\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=\"green\"), bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7), fontsize=10, color=\"green\")\n",
    "\n",
    "        if params_off is not None:\n",
    "            elbow_off_speed, elbow_off_rate = find_elbow_point(params_off, speeds)\n",
    "            ax.scatter(elbow_off_speed, elbow_off_rate, color=\"red\", s=100, label=\"\", zorder=5)\n",
    "            ax.annotate(f\"Elbow Point (Off): {elbow_off_speed:.1f} km/h\\nRate: {elbow_off_rate:.3f}\",\n",
    "                        (elbow_off_speed, elbow_off_rate), textcoords=\"offset points\", xytext=(30, -10),\n",
    "                        arrowprops=dict(arrowstyle=\"->\", color=\"red\"), bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7), fontsize=10, color=\"red\")\n",
    "        \"\"\"\n",
    "        # Rotate x-axis labels by 45 degrees for both subplots\n",
    "        \n",
    "        ax.set_title(title, fontsize=12)\n",
    "        ax.set_xlabel(\"Speed [km/h]\", fontsize=14)\n",
    "        ax.set_ylabel(\"Energy Consumption [kWh/100km] or [L/100 km]\", fontsize=14)\n",
    "        ax.grid(True)\n",
    "        ax.legend(loc=\"center right\", fontsize=10, frameon=True)\n",
    "\n",
    "    # Plot for below and above threshold\n",
    "    plot_regression(axes[0], data_below_on, data_below_off, params_below_on, params_below_off, f\"Energy Consumption vs. Speed - {vehicle_type_map[vehicle_type]} (<= {temp_threshold}°C)\")\n",
    "    plot_regression(axes[1], data_above_on, data_above_off, params_above_on, params_above_off, f\"Energy Consumption vs. Speed - {vehicle_type_map[vehicle_type]} (> {temp_threshold}°C)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_consumption_vehicle_stats(hybrid_electric_only, hybrid_fuel_only, hybrid_combined_case1, hybrid_combined_case2):\n",
    "    # Count Vehicles in Each Hybrid Mode\n",
    "    hybrid_modes = [\"Electric Only\", \"Fuel Only\", \"Hybrid Fuel-Dominated\", \"Hybrid Combined\"]\n",
    "    vehicle_counts = [len(hybrid_electric_only), len(hybrid_fuel_only), len(hybrid_combined_case1), len(hybrid_combined_case2)]\n",
    "\n",
    "    # Calculate percentages\n",
    "    total_vehicles = sum(vehicle_counts)\n",
    "    percentages = [(count / total_vehicles) * 100 for count in vehicle_counts]\n",
    "\n",
    "    # Create figure\n",
    "    color_list = [\"#035970\", \"salmon\" , \"#FFA07A\", \"#4F8B9B\"]\n",
    "    bars = plt.bar(hybrid_modes, vehicle_counts, color=color_list, alpha=0.7)\n",
    "\n",
    "    # Add annotations for both counts and percentages\n",
    "    for i, bar in enumerate(bars):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 500, \n",
    "                f\"{vehicle_counts[i]}\\n({percentages[i]:.1f}%)\", \n",
    "                ha=\"center\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "    # Labels and title\n",
    "    plt.xlabel(\"Hybrid Mode\", fontsize=12)\n",
    "    plt.xticks(rotation=60)\n",
    "    plt.ylabel(\"Number of Trips (Absolute & Percentage)\", fontsize=12)\n",
    "    plt.ylim(0, max(vehicle_counts) * 1.2)  # Extend y-limit for better spacing\n",
    "    plt.title(\"Distribution of Modes used in PHEV\", fontsize=14)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_FOLDER}/parameters_exp.json\", \"w\", encoding=\"utf-8\") as fw:\n",
    "    json.dump(parameters, fw, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "df_7 = df_6.copy()\n",
    "df_7 = df_7[df_7[\"speed\"] > 0]\n",
    "df_7 = df_7.dropna(subset=[\"speed\", \"electric_consumption\", \"fuel_consumption\"])\n",
    "# Apply Temperature Threshold for Electric-relevant Models Only\n",
    "temp_threshold = 8\n",
    "\n",
    "df_7[\"efficient_mode_status\"] = np.where(df_7[\"efficient_mode\"] == 0, \"Off\", \"On\")\n",
    "\n",
    "# ICE\n",
    "fuel_vehicles = df_7[(df_7[\"vehicle_type\"] == \"BE\") & (df_7[\"fuel_consumption\"] > 0)]\n",
    "\n",
    "# BEV\n",
    "electric_vehicles = df_7[(df_7[\"vehicle_type\"] == \"EL\") & (df_7[\"electric_consumption\"] > 0)]\n",
    "\n",
    "# HY Cases\n",
    "# Case 1: Electric Only\n",
    "hybrid_electric_only = df_7[(df_7[\"vehicle_type\"] == \"HY\") & (df_7[\"electric_consumption\"] > 0) & (df_7[\"fuel_consumption\"] == 0)]\n",
    "\n",
    "# Case 2: Fuel Only\n",
    "hybrid_fuel_only = df_7[(df_7[\"vehicle_type\"] == \"HY\") & (df_7[\"fuel_consumption\"] > 0) & (df_7[\"electric_consumption\"] == 0)]\n",
    "\n",
    "# Case 3: Fuel-dominated\n",
    "hybrid_combined_case1 = df_7[(df_7[\"vehicle_type\"] == \"HY\") & (df_7[\"electric_consumption\"] < 0) & (df_7[\"fuel_consumption\"] > 0)].copy()\n",
    "hybrid_combined_case1[\"combined_consumption_fuel\"] = hybrid_combined_case1[\"fuel_consumption\"]\n",
    "\n",
    "# Case 4: Combined Mode\n",
    "hybrid_combined_case2 = df_7[(df_7[\"vehicle_type\"] == \"HY\") & (df_7[\"electric_consumption\"] > 0) & (df_7[\"fuel_consumption\"] > 0)].copy()\n",
    "hybrid_combined_case2[\"combined_consumption\"] = hybrid_combined_case2[\"electric_consumption\"] + hybrid_combined_case2[\"fuel_consumption\"]\n",
    "\n",
    "# Plot Electric Consumption for Electric Vehicles\n",
    "analyze_electric_comsumption(electric_vehicles, temp_threshold, \"speed\", \"electric_consumption\", \"Electric Vehicles\")\n",
    "\n",
    "# Plot Electric Consumption for Hybrid Electric Only Vehicles\n",
    "analyze_electric_comsumption(hybrid_electric_only, temp_threshold, \"speed\", \"electric_consumption\", \"Hybrid Electric-Only Vehicles\")\n",
    "\n",
    "# Plot Combined Consumption for Hybrid Combined Mode Vehicles\n",
    "analyze_electric_comsumption(hybrid_combined_case2, temp_threshold, \"speed\", \"combined_consumption\", \"Hybrid Combined Vehicles\")\n",
    "\n",
    "# Plot Fuel Consumption for BE and Hybrid Modes Vehicles\n",
    "analyze_fuel_consumption(fuel_vehicles, \"speed\", \"fuel_consumption\", \"Fuel Vehicles\")\n",
    "analyze_fuel_consumption(hybrid_fuel_only, \"speed\", \"fuel_consumption\", \"Hybrid Fuel-Only Vehicles\")\n",
    "analyze_fuel_consumption(hybrid_combined_case1,\"speed\", \"combined_consumption_fuel\", \"Hybrid Fuel-Dominated Vehicles\")\n",
    "\n",
    "# Plot Number of Vehicles w.r.t Vehicle Types\n",
    "plot_consumption_vehicle_stats(hybrid_electric_only, hybrid_fuel_only, hybrid_combined_case1, hybrid_combined_case2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your calculation functions\n",
    "def calculate_savings_fuel_vehicles(a, b, c, x, speed, distance, fuel_price):\n",
    "    fuel_consumption_per_100km = a * np.exp(-b * speed) + c\n",
    "    fuel_consumption_per_km = fuel_consumption_per_100km / 100\n",
    "    total_fuel_savings = x * distance * fuel_consumption_per_km\n",
    "    fuel_cost_savings = total_fuel_savings * fuel_price\n",
    "    return round(total_fuel_savings, 3), round(fuel_cost_savings, 3)\n",
    "\n",
    "def calculate_savings_electric_vehicles(a, b, c, x, speed, distance, electric_price):\n",
    "    electric_consumption_per_100km = a * np.exp(-b * speed) + c\n",
    "    electric_consumption_per_km = electric_consumption_per_100km / 100\n",
    "    total_electric_savings = x * distance * electric_consumption_per_km\n",
    "    electric_cost_savings = total_electric_savings * electric_price\n",
    "    return round(total_electric_savings, 3), round(electric_cost_savings, 3)\n",
    "\n",
    "\n",
    "# Define calculation functions for different vehicle types\n",
    "saving_calculation_funcs = {\n",
    "    \"Fuel Vehicles\": calculate_savings_fuel_vehicles,\n",
    "    \"Electric Vehicles\": calculate_savings_electric_vehicles,\n",
    "    \"Hybrid Fuel-Only Vehicles\": calculate_savings_fuel_vehicles,\n",
    "    \"Hybrid Electric-Only Vehicles\": calculate_savings_electric_vehicles,\n",
    "}\n",
    "\n",
    "def calculate_savings(parameters, reduced_trips, speed_ranges, fuel_price, electric_price):\n",
    "    # Define distance for each speed range\n",
    "    speed_range_distances = {sr: 100 for sr in speed_ranges}  # 100 km for each range\n",
    "    savings_data = {\n",
    "        \"Vehicle Type\": [],\n",
    "        \"Efficient Mode\": [],\n",
    "        \"Speed Range in km/h\": [],\n",
    "        \"Distance (km)\": [],\n",
    "        \"Savings Type\": [],\n",
    "        \"Savings Value\": []\n",
    "    }\n",
    "    # Calculate savings for each vehicle type and efficient mode\n",
    "    for vehicle_type, modes in parameters.items():\n",
    "        if vehicle_type not in saving_calculation_funcs:\n",
    "            continue\n",
    "        \n",
    "        calculate_savings = saving_calculation_funcs[vehicle_type]\n",
    "        savings_label = \"Fuel Consumption Savings (L/100 km)\" if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else \"Electric Consumption Savings (kWh/100 km)\"\n",
    "\n",
    "        for efficient_mode, param in modes.items():\n",
    "            if \"Below\" in param and \"Above\" in param:\n",
    "                a1, b1, c1 = param[\"Below\"]\n",
    "                a2, b2, c2 = param[\"Above\"]\n",
    "                \n",
    "                for min_speed, max_speed in speed_ranges:\n",
    "                    distance = speed_range_distances[(min_speed, max_speed)]\n",
    "                    speed_for_calculation = max_speed\n",
    "\n",
    "                    savings_low = calculate_savings(a1, b1, c1, reduced_trips, speed_for_calculation, distance, fuel_price if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else electric_price)\n",
    "                    savings_high = calculate_savings(a2, b2, c2, reduced_trips, speed_for_calculation, distance, fuel_price if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else electric_price)\n",
    "\n",
    "                    savings_data[\"Vehicle Type\"].extend([vehicle_type] * 2)\n",
    "                    savings_data[\"Efficient Mode\"].extend([f\"{efficient_mode} | Low Temperature\", f\"{efficient_mode} | High Temperature\"])\n",
    "                    #savings_data[\"Speed Range in km/h\"].extend([f\"{min_speed}-{max_speed}\"] * 2)\n",
    "                    savings_data[\"Speed Range in km/h\"].extend([f\"{max_speed}\"] * 2)\n",
    "                    savings_data[\"Distance (km)\"].extend([distance] * 2)\n",
    "                    savings_data[\"Savings Type\"].extend([savings_label] * 2)\n",
    "                    savings_data[\"Savings Value\"].extend([savings_low[0], savings_high[0]])\n",
    "            else:\n",
    "                a, b, c = param\n",
    "                for speed_range in speed_ranges:\n",
    "                    min_speed, max_speed = speed_range\n",
    "                    speed_for_calculation = max_speed\n",
    "                    distance = speed_range_distances[speed_range]\n",
    "                    speed_for_calculation = max_speed\n",
    "                    savings = calculate_savings(a, b, c, reduced_trips, speed_for_calculation, distance, fuel_price if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else electric_price)\n",
    "                    savings_data[\"Vehicle Type\"].append(vehicle_type)\n",
    "                    savings_data[\"Efficient Mode\"].append(efficient_mode)\n",
    "                    #savings_data[\"Speed Range in km/h\"].append(f\"{min_speed}-{max_speed}\")\n",
    "                    savings_data[\"Speed Range in km/h\"].extend([f\"{max_speed}\"])\n",
    "                    savings_data[\"Distance (km)\"].append(distance)\n",
    "                    savings_data[\"Savings Type\"].append(savings_label)\n",
    "                    savings_data[\"Savings Value\"].append(savings[0])\n",
    "                    # Use the cost savings values here, not the consumption savings\n",
    "                    if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"]:\n",
    "                        savings_data[\"Fuel Cost Savings Value\"] = savings_data[\"Savings Value\"] * fuel_price\n",
    "                    else:\n",
    "                        savings_data[\"Electric Cost Savings Value\"] = savings_data[\"Savings Value\"] * electric_price\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df_savings = pd.DataFrame(savings_data)\n",
    "    return df_savings\n",
    "\n",
    "\n",
    "# Define color palette for low and high temperature modes (default for fuel vehicles)\n",
    "def plot_savings(df_savings):\n",
    "    colors = {\n",
    "        \"Low Temperature\": (\"#58D68D\", \"#F5B041\"),  # Light and dark blue\n",
    "        \"High Temperature\": (\"#2E8B57\", \"#C0392B\"),   # Light and dark warm tones\n",
    "        \"Fuel Vehicles\": (\"#2E8B57\", \"#C0392B\"),  # Default color for fuel vehicles\n",
    "        \"Hybrid Fuel-Only Vehicles\": (\"#2E8B57\", \"#C0392B\")  # Default color for hybrid fuel-only vehicles,\n",
    "    }\n",
    "\n",
    "    vehicle_type_map = {\n",
    "        \"Fuel Vehicles\": \"ICE\",\n",
    "        \"Electric Vehicles\": \"BEV\",\n",
    "        \"Hybrid Fuel-Only Vehicles\": \"PHEV (Fuel Only)\",\n",
    "        \"Hybrid Electric-Only Vehicles\": \"PHEV (Electric-Only)\"\n",
    "    }\n",
    "\n",
    "    vehicle_types = df_savings[\"Vehicle Type\"].unique()\n",
    "\n",
    "    # Plot savings for each vehicle type\n",
    "    for vehicle_type in vehicle_types:\n",
    "        df_vehicle_savings = df_savings[df_savings[\"Vehicle Type\"] == vehicle_type]\n",
    "        \n",
    "        # Calculate cost savings\n",
    "        savings_label = \"Fuel Consumption Savings (L/100 km)\" if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else \"Electric Consumption Savings (kWh/100 km)\"\n",
    "        cost_label = \"Fuel Cost Savings (€/100 km)\" if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"] else \"Electric Cost Savings (€/100 km)\"\n",
    "        \n",
    "        # Create subplots for consumption and cost savings\n",
    "        _, axes = plt.subplots(2, 1, figsize=(10, 7), sharex=True)\n",
    "        \n",
    "        # First subplot - Consumption Savings\n",
    "        ax1 = axes[0]\n",
    "        if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"]:\n",
    "            sns.barplot(\n",
    "                data=df_vehicle_savings,\n",
    "                x=\"Speed Range in km/h\", y=\"Savings Value\", hue=\"Efficient Mode\",\n",
    "                palette=[colors[vehicle_type][0], colors[vehicle_type][1]], ax=ax1\n",
    "            )\n",
    "        else:\n",
    "            for mode, (light_color, dark_color) in colors.items():\n",
    "                sns.barplot(\n",
    "                    data=df_vehicle_savings[df_vehicle_savings[\"Efficient Mode\"].str.contains(mode)],\n",
    "                    x=\"Speed Range in km/h\", y=\"Savings Value\", hue=\"Efficient Mode\",\n",
    "                    palette=[light_color, dark_color], ax=ax1\n",
    "                )\n",
    "        for p in ax1.patches:\n",
    "            value = p.get_height()\n",
    "            if value > 0.000:  # Only annotate if value is larger than 0.000\n",
    "                ax1.annotate(f\"{value:.0f}\", (p.get_x() + p.get_width() / 2., value), \n",
    "                            ha=\"center\", va=\"center\", fontsize=8, fontweight = \"bold\", color=\"black\", \n",
    "                            xytext=(0, 5), textcoords=\"offset points\")\n",
    "        \n",
    "        ax1.set_title(f\"{vehicle_type_map[vehicle_type]} - {savings_label}\", fontsize=8)\n",
    "        ax1.set_ylabel(savings_label)\n",
    "        ax1.set_xlabel(\"Speed Range in km/h\")\n",
    "        ax1.legend(title=\"Efficient Mode\", loc=\"lower left\")\n",
    "        \n",
    "        # Second subplot - Cost Savings\n",
    "        ax2 = axes[1]\n",
    "        if vehicle_type in [\"Fuel Vehicles\", \"Hybrid Fuel-Only Vehicles\"]:\n",
    "            sns.barplot(\n",
    "                data=df_vehicle_savings,\n",
    "                x=\"Speed Range in km/h\", y=\"Fuel Cost Savings Value\", hue=\"Efficient Mode\",\n",
    "                palette=[colors[vehicle_type][0], colors[vehicle_type][1]], ax=ax2\n",
    "            )\n",
    "        else:\n",
    "            for mode, (light_color, dark_color) in colors.items():\n",
    "                sns.barplot(\n",
    "                    data=df_vehicle_savings[df_vehicle_savings[\"Efficient Mode\"].str.contains(mode)],\n",
    "                    x=\"Speed Range in km/h\", y=\"Electric Cost Savings Value\", hue=\"Efficient Mode\",\n",
    "                    palette=[light_color, dark_color], ax=ax2\n",
    "                )\n",
    "        for p in ax2.patches:\n",
    "            value = p.get_height()\n",
    "            if value > 0:\n",
    "                ax2.annotate(f\"€{value:.2f}\", (p.get_x() + p.get_width() / 2., value), \n",
    "                            ha=\"center\", va=\"center\", fontsize=8, fontweight = \"bold\",\n",
    "                            xytext=(0, 5), textcoords=\"offset points\")\n",
    "        ax2.set_title(f\"{vehicle_type_map[vehicle_type]} - {savings_label}\", fontsize=8)\n",
    "        ax2.set_ylabel(cost_label)\n",
    "        ax2.tick_params(axis=\"x\", labelsize=8)\n",
    "        ax2.set_xlabel(\"Speed Range in km/h\", fontsize=8, labelpad=0)\n",
    "        ax2.legend(title=\"Efficient Mode\", loc=\"lower left\")\n",
    "\n",
    "        plt.xticks(rotation=0, ha=\"center\")\n",
    "        plt.subplots_adjust(bottom=0.06, top=0.97, hspace=0.07)  # Increase value if needed\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "reduced_trips = 1  # Reduced trips\n",
    "speed_ranges = [(0, 30), (30, 55), (55, 80), (80, 120)]  # Updated last range\n",
    "fuel_price = 1.3  # Price € per liter for fuel\n",
    "electric_price = 0.20  # Price € per kWh for electricity\n",
    "\n",
    "df_savings = calculate_savings(parameters, reduced_trips, speed_ranges, fuel_price, electric_price)\n",
    "plot_savings(df_savings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
